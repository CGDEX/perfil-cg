{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX4nznx_Aznt"
      },
      "source": [
        "-Each directory contains one CSV file with annotations (\"GT-<ClassID>.csv\") and the training images\n",
        "\n",
        "-Each image is a traffic sign\n",
        "\n",
        "-Image sizes varies 15x15 to 250x250\n",
        "\n",
        "**Annotation Formation**\n",
        "\n",
        "-Filename: Filename of corresponding image\n",
        "\n",
        "-Width: Width of the image\n",
        "\n",
        "-Height: Height of the image\n",
        "\n",
        "-ROI.x1: X-coordinate of top-left corner of traffic sign bounding box\n",
        "\n",
        "-ROI.y1: Y-coordinate of top-left corner of traffic sign bounding box\n",
        "\n",
        "-ROI.x2: X-coordinate of bottom-right corner of traffic sign bounding box\n",
        "\n",
        "-ROI.y2: Y-coordinate of bottom-right corner of traffic sign bounding box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW7KKF6GA1Ey",
        "outputId": "d61dbf00-5105-40b3-9888-d4e0d0034692"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJ-4XTkBgF9",
        "outputId": "d228506f-7e5c-4bc7-8fcb-f92e10eb5914"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_cTrl0-GAznw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rengar\\.conda\\envs\\vcpi2\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,Activation, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,TensorBoard, ReduceLROnPlateau\n",
        "import pathlib\n",
        "import tensorflow_addons as tfa\n",
        "import sys\n",
        "from PIL import Image\n",
        "vcpi = sys.modules[__name__] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3ykMlTYAznz",
        "outputId": "c72d4014-241c-4374-8e82-34df426fd37b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDe0pGbxAzn0"
      },
      "source": [
        "Default Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AFRCQE_5Azn1"
      },
      "outputs": [],
      "source": [
        "N_classes = 43\n",
        "data = []\n",
        "directory_training = \"./datasets/train\"\n",
        "directory_test = \"./datasets/test\"\n",
        "model_directory = \"./models/\"\n",
        "ensemble_directory = \"./ensemble/\"\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 32\n",
        "N_CHANNELS = 3\n",
        "KERNEL_SIZE = (3,3)\n",
        "N_EPOCHS = 5\n",
        "TRAIN_ONLINE = False\n",
        "NUM_MODELS = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGFoaJGEAzn2"
      },
      "source": [
        "Filters\n",
        "Ideas:\n",
        "- Convert to RGB (grayscale I guess?)\n",
        "- Translation\n",
        "- Zooming\n",
        "- Padding\n",
        "- Change contrast \n",
        "- Use mean/median filters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qg3NixPKAzn3"
      },
      "outputs": [],
      "source": [
        "N_FILTERS = 4\n",
        "filters_name = [\"rotate\",\"brightness\",\"translate\",\"saturation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hqoUR448Azn4"
      },
      "outputs": [],
      "source": [
        "def filter_rotate(image,label):\n",
        "    #Rotate image 10 degrees\n",
        "    image = tfa.image.rotate(image, 10)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VtEqL7X4Azn4"
      },
      "outputs": [],
      "source": [
        "def filter_brightness(image,label):\n",
        "    # Increase brightness of image\n",
        "    image = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 1.0, 0.1, 3.0),0,1)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h8fixrb3Azn5"
      },
      "outputs": [],
      "source": [
        "def filter_shear(image, label):\n",
        "    \n",
        "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
        "    sx = tf.random.uniform(shape=(), minval=-0.1, maxval=0.1, dtype=tf.dtypes.float32)\n",
        "    img = tfa.image.transform(img, [1, sx, -sx*32,   0,1,0,  0,0])\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WhL30UDqAzn6"
      },
      "outputs": [],
      "source": [
        "def filter_translate(image, label):\n",
        "\n",
        "    img = tfa.image.rotate(image, tf.random.uniform(shape=(), minval=-0.175, maxval=0.175))\n",
        "    tx = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)\n",
        "    ty = tf.random.uniform(shape=(), minval=-3, maxval=3, dtype=tf.dtypes.float32)  \n",
        "    img = tfa.image.translate(img, [tx,ty])\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hw2yeHPcAzn8"
      },
      "outputs": [],
      "source": [
        "def filter_saturation(image, label):\n",
        "    \n",
        "    img = tf.clip_by_value(tfa.image.random_hsv_in_yiq(image, 0.0, 1.0, 3.0, 1.0, 1.0),0,1)\n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8Gt8V3DAAzn8"
      },
      "outputs": [],
      "source": [
        "filters = []\n",
        "\n",
        "for filtro in filters_name:\n",
        "    func = getattr(vcpi, \"filter_{}\".format(filtro))\n",
        "    filters.append(func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s8XA3Q1Azn9"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_1_ensemble():\n",
        "    modelLogits = Sequential()\n",
        "    \n",
        "    modelLogits.add(Conv2D(32, KERNEL_SIZE, input_shape=(IMAGE_SIZE, IMAGE_SIZE, N_CHANNELS)))         \n",
        "    modelLogits.add(LeakyReLU(alpha=0.01))  \n",
        "    modelLogits.add(BatchNormalization())\n",
        "    modelLogits.add(Dropout(0.5)) \n",
        "\n",
        "    modelLogits.add(Conv2D(64, KERNEL_SIZE)) \n",
        "    modelLogits.add(LeakyReLU(alpha=0.01))\n",
        "    modelLogits.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    modelLogits.add(BatchNormalization())\n",
        "    modelLogits.add(Dropout(0.5)) \n",
        "\n",
        "    modelLogits.add(Conv2D(128, KERNEL_SIZE))   \n",
        "    modelLogits.add(LeakyReLU(alpha=0.01))\n",
        "    modelLogits.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    modelLogits.add(BatchNormalization())\n",
        "    modelLogits.add(Dropout(0.5)) \n",
        "    \n",
        "    modelLogits.add(Flatten())\n",
        "    modelLogits.add(Dense(192))\n",
        "    modelLogits.add(LeakyReLU(alpha=0.0))             \n",
        "    modelLogits.add(Dropout(0.5)) \n",
        "    \n",
        "    modelLogits.add(Dense(N_classes))\n",
        "    \n",
        "    output = Activation('softmax')(modelLogits.output)\n",
        "\n",
        "    model = tf.keras.Model(modelLogits.inputs, output)\n",
        "    \n",
        "    opt = Adam(lr=0.0001)\n",
        "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ 'accuracy'])\n",
        "    \n",
        "    return model, modelLogits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zb1moFrSAzoB",
        "outputId": "6f53bad5-5eee-414b-b306-3b9b229ff239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['00000', '00001', '00002', '00003', '00004', '00005', '00006',\n",
              "       '00007', '00008', '00009', '00010', '00011', '00012', '00013',\n",
              "       '00014', '00015', '00016', '00017', '00018', '00019', '00020',\n",
              "       '00021', '00022', '00023', '00024', '00025', '00026', '00027',\n",
              "       '00028', '00029', '00030', '00031', '00032', '00033', '00034',\n",
              "       '00035', '00036', '00037', '00038', '00039', '00040', '00041',\n",
              "       '00042'], dtype='<U5')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classNames = np.array(os.listdir(directory_training))\n",
        "classNames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFkNOC1dAzoD"
      },
      "source": [
        "Saving images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1OR-qzcNAzoD"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "data = tf.data.Dataset.list_files(f\"{directory_training}/*/*.png\", shuffle=False)\n",
        "image_count = len(data)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqa-l4uzAzoE"
      },
      "source": [
        "# Preparing datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDCLK3Z3AzoE"
      },
      "source": [
        "## Aux functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fzO8_yMBAzoE"
      },
      "outputs": [],
      "source": [
        "def get_label(file_path):\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    return parts[-2] == classNames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pVfN1_e0AzoF"
      },
      "outputs": [],
      "source": [
        "def get_img_label(file_path):\n",
        "    label = get_label(file_path)\n",
        "    img = tf.io.read_file(file_path)\n",
        "    \n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    img = tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    return img,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39209\n"
          ]
        }
      ],
      "source": [
        "dataset = data.map(get_img_label, num_parallel_calls=AUTOTUNE)\n",
        "dataset_length = len(dataset)\n",
        "print(dataset_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l5Co4ilAzoF"
      },
      "source": [
        "Spliting dataset into training and validation sets, we using 80% and 20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BPjEQBw7AzoF"
      },
      "outputs": [],
      "source": [
        "val_size = int(image_count * 0.2)\n",
        "train_ds = dataset.skip(val_size)\n",
        "val_ds = dataset.take(val_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0FZoKQcAzoG",
        "outputId": "0a02b95e-83c0-47b8-bf42-98b22385d29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31368\n",
            "7841\n"
          ]
        }
      ],
      "source": [
        "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "val_ds_size = tf.data.experimental.cardinality(val_ds).numpy()\n",
        "\n",
        "print(train_ds_size)\n",
        "print(val_ds_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC7aVKjpAzoH"
      },
      "source": [
        "Configuring dataset, to train a model it's important to have data to be well shuffled and to be batched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2VoVvMCmAzoI"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataSolo = train_ds.cache()\n",
        "# note: works the best if buffer size >= the full of size of the dataset\n",
        "dataSolo = dataSolo.shuffle(buffer_size = train_ds_size)\n",
        "# note2: we might need to tune or we just use autotune \n",
        "dataSolo = dataSolo.prefetch(buffer_size = train_ds_size)\n",
        "dataSolo = dataSolo.batch(batch_size=BATCH_SIZE)\n",
        "# note3: this allows later elements to be prepared while current element is being processed\n",
        "# note4: it should end with a call to prefetch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_set = val_ds.cache()\n",
        "val_set = val_set.shuffle(buffer_size = val_ds_size)\n",
        "val_set = val_set.prefetch(buffer_size = AUTOTUNE)\n",
        "val_set = val_set.batch(batch_size=val_ds_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "vUSvSxVYAzoJ",
        "outputId": "b045513d-ed38-45f8-f566-95a9f6722044"
      },
      "outputs": [],
      "source": [
        "#i = 0\n",
        "#test = next(iter(dataSolo))  \n",
        "#\n",
        "#print(test[0].shape, test[1].shape)\n",
        "\n",
        "# TODO: FIX THIS IMAGES\n",
        "# plt.figure(figsize=(10, 10))\n",
        "# for i in range(25):\n",
        "#   ax = plt.subplot(5, 5, i + 1)\n",
        "#   plt.imshow(image_batch[i])\n",
        "#   plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqi6lLfiAzoJ"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_callbacks(file_path):\n",
        "\n",
        "    checkpointer = ModelCheckpoint(filepath= file_path, monitor = 'val_accuracy', verbose=1, save_weights_only=True, save_best_only=True)\n",
        "    earlyStopper = EarlyStopping(monitor='val_accuracy', min_delta = 0.00001, patience = 15, verbose = 1)\n",
        "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.000000001, verbose = 1)\n",
        "\n",
        "    return [checkpointer, earlyStopper, reduceLR]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_prefix = f'{ensemble_directory}V1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_models(train, val,file_path_prefix):\n",
        "\n",
        "    models = []\n",
        "    histories = []\n",
        "    \n",
        "    for i in range(NUM_MODELS):\n",
        "\n",
        "        model, modelL = model_1_ensemble()\n",
        "\n",
        "        if TRAIN_ONLINE:\n",
        "            callbacks = prepare_callbacks(f'{file_path_prefix}_{i:02}/cp.ckpt')\n",
        "\n",
        "            hist = model.fit(train, \n",
        "                            epochs = N_EPOCHS,\n",
        "                            validation_data=val,\n",
        "                            callbacks = callbacks)\n",
        "            histories.append(hist)\n",
        "\n",
        "        models.append([model, modelL])\n",
        "    \n",
        "    return models,histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Rengar\\.conda\\envs\\vcpi2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "modelV1, historyV1 = train_models(dataSolo, val_set, file_path_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_weights(models, file_path_prefix):\n",
        "\n",
        "    for i in range(NUM_MODELS):\n",
        "\n",
        "        file_path = f'{file_path_prefix}_{i:02}/cp.ckpt'\n",
        "\n",
        "        models[i][0].load_weights(file_path)\n",
        "        models[i][0].save('temp.hdf5')\n",
        "        models[i][1].load_weights('temp.hdf5', by_name=True)\n",
        "    \n",
        "\n",
        "load_weights(modelV1, file_path_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bIxNMhrzAzoI"
      },
      "outputs": [],
      "source": [
        "test_set = tf.data.Dataset.list_files(f\"{directory_test}/*/*.png\")\n",
        "test_set = test_set.map(get_img_label, num_parallel_calls=AUTOTUNE)\n",
        "test_set_len = len(test_set)\n",
        "data_test_set = test_set.batch(batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "395/395 - 5s - loss: 2.7189 - accuracy: 0.7455\n",
            "395/395 - 3s - loss: 3.5412 - accuracy: 0.7674\n",
            "395/395 - 3s - loss: 3.2371 - accuracy: 0.7560\n",
            "395/395 - 3s - loss: 3.1986 - accuracy: 0.7626\n",
            "average accuracy: 75.788\n"
          ]
        }
      ],
      "source": [
        "accuracy = 0\n",
        "\n",
        "for i in range(NUM_MODELS):\n",
        "    eval = modelV1[i][0].evaluate(data_test_set, verbose = 2)\n",
        "    accuracy += eval[1]\n",
        "    \n",
        "print(f'average accuracy: {(accuracy/NUM_MODELS)*100:.3f}')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_labels_logits_and_preds(models):\n",
        "\n",
        "    preds = [[] for _ in range(NUM_MODELS) ]\n",
        "    logits = [[] for _ in range(NUM_MODELS)]\n",
        "    labels = []\n",
        "\n",
        "    for images, labs in data_test_set.take(-1):\n",
        "\n",
        "        labels.extend(labs.numpy())\n",
        "        for i in range(NUM_MODELS):\n",
        "            preds[i].extend(models[i][0].predict(images))\n",
        "            logits[i].extend(models[i][1].predict(images))\n",
        "\n",
        "    labels = [np.argmax(i) for i in labels]  \n",
        "    \n",
        "    return labels, logits, preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020AE24723A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020AE76070D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ],
      "source": [
        "labels_V1, logits_V1, preds_V1 = get_labels_logits_and_preds(modelV1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_class_preds(preds):\n",
        "\n",
        "    class_preds = []\n",
        "\n",
        "    for i in range(test_set_len):\n",
        "\n",
        "        c = []\n",
        "        for m in range(NUM_MODELS):\n",
        "\n",
        "            c.append(np.argmax(preds[m][i]))\n",
        "        class_preds.append(c)\n",
        "        \n",
        "    return class_preds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_class_from_sum_of_logits(logits):\n",
        "\n",
        "    sum_logits = []\n",
        "\n",
        "    for i in range(test_set_len):\n",
        "\n",
        "        log = logits[0][i]\n",
        "        for m in range(1, NUM_MODELS):\n",
        "            log = np.add(log, logits[m][i])\n",
        "        sum_logits.append(np.argmax(log))\n",
        "    return(sum_logits)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_preds_V1 = get_class_preds(preds_V1)\n",
        "class_logits_V1 = get_class_from_sum_of_logits(logits_V1)    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12630, 9025, 1839, 532, 405, 829, 9699, 2931] 0.7679334916864609\n"
          ]
        }
      ],
      "source": [
        "import collections \n",
        "def get_stats(labels, class_preds, class_logits):\n",
        "\n",
        "    all_correct = 0\n",
        "    all_incorrect = 0\n",
        "    maj_vote = 0\n",
        "    maj_wrong = 0\n",
        "    tie = 0\n",
        "    count = 0\n",
        "    log_ok = 0\n",
        "    log_ko = 0\n",
        "\n",
        "    for k in range(test_set_len):\n",
        "\n",
        "        counter = collections.Counter(class_preds[k])\n",
        "        if len(counter) == 1:\n",
        "            if counter.most_common(1)[0][0] == labels[k]:\n",
        "                all_correct += 1\n",
        "            else:\n",
        "                all_incorrect += 1\n",
        "        else:\n",
        "            aux = counter.most_common(2)\n",
        "            if aux[0][1] > aux[1][1] and aux[0][0] == labels[k]:\n",
        "                maj_vote += 1\n",
        "            if aux[0][1] > aux[1][1] and aux[0][0] != labels[k]:\n",
        "                maj_wrong += 1\n",
        "            elif aux[0][1] == aux[1][1]:\n",
        "                tie += 1\n",
        "        if class_logits[k] == labels[k]:\n",
        "            log_ok += 1\n",
        "        else:\n",
        "            log_ko += 1\n",
        "        count += 1 \n",
        "        \n",
        "    return [count, all_correct, all_incorrect, maj_vote, tie, maj_wrong, log_ok, log_ko]\n",
        "    \n",
        "    \n",
        "res = get_stats(labels_V1, class_preds_V1, class_logits_V1)\n",
        "print(res, res[6]/res[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataV2 = dataset\n",
        "dataV2 = dataV2.shuffle(buffer_size = len(dataV2))\n",
        "\n",
        "for filtro in filters:\n",
        "    dataV2 = dataV2.concatenate(dataV2.map(filtro))\n",
        "\n",
        "image_count = len(dataV2)\n",
        "\n",
        "dataV2 = dataV2.cache()\n",
        "dataV2 = dataV2.batch(batch_size=BATCH_SIZE)\n",
        "dataV2 = dataV2.prefetch(buffer_size=image_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path_prefix = f'{ensemble_directory}V3'\n",
        "\n",
        "models_V2, histories_V2 = train_models(dataV2, val_set,file_path_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_weights(models_V2, file_path_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "395/395 - 3s - loss: 0.0903 - accuracy: 0.9722\n",
            "395/395 - 3s - loss: 0.0876 - accuracy: 0.9710\n",
            "395/395 - 3s - loss: 0.0835 - accuracy: 0.9743\n",
            "395/395 - 3s - loss: 0.0990 - accuracy: 0.9712\n",
            "average accuracy: 97.219\n"
          ]
        }
      ],
      "source": [
        "accuracy = 0\n",
        "\n",
        "for i in range(NUM_MODELS):\n",
        "    eval = models_V2[i][0].evaluate(data_test_set, verbose = 2)\n",
        "    accuracy += eval[1]\n",
        "    \n",
        "print(f'average accuracy: {(accuracy/NUM_MODELS)*100:.3f}')   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_V2, logits_V2, preds_V2 = get_labels_logits_and_preds(models_V2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_preds_V2 = get_class_preds(preds_V2)\n",
        "class_logits_V2 = get_class_from_sum_of_logits(logits_V2)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12630, 11979, 110, 319, 107, 115, 12362, 268] 0.9787806809184482\n"
          ]
        }
      ],
      "source": [
        "res = get_stats(labels_V2, class_preds_V2, class_logits_V2)\n",
        "print(res, res[6]/res[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stacked Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_logits_preds = []\n",
        "\n",
        "for i in range(len(test_set)):\n",
        "    \n",
        "    aux = []   \n",
        "    for m in range(NUM_MODELS):        \n",
        "        aux.extend(logits_V2[m][i])\n",
        "        \n",
        "    test_logits_preds.append(aux)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "logits_train = [[] for _ in range(NUM_MODELS)]\n",
        "labels_aux = []\n",
        "for images, labs in dataV2.take(-1):\n",
        "\n",
        "    labels_aux.extend(labs.numpy())\n",
        "    for i in range(NUM_MODELS):\n",
        "        logits_train[i].extend(models_V2[i][1].predict(images))\n",
        "        \n",
        "labels_train = [np.argmax(i) for i in labels_aux] \n",
        "\n",
        "print(logits_train[0])\n",
        "for i in range(NUM_MODELS):\n",
        "    logits_train[i][0]\n",
        "## Build list of train inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_logits_preds = []\n",
        "\n",
        "for i in range(image_count):\n",
        "    \n",
        "    aux = []\n",
        "    \n",
        "    for m in range(NUM_MODELS):\n",
        "        \n",
        "        aux.extend(logits_train[m][i])\n",
        "        \n",
        "    train_logits_preds.append(aux)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(labels_train), len(train_logits_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_model  = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(len(train_logits_preds[0]),)),\n",
        "\n",
        "  tf.keras.layers.Dense(192),    \n",
        "  BatchNormalization(),LeakyReLU(alpha=0.01),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(128),    \n",
        "  BatchNormalization(),LeakyReLU(alpha=0.01),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  tf.keras.layers.Dense(64),    \n",
        "  BatchNormalization(),LeakyReLU(alpha=0.01),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "  tf.keras.layers.Dense(8, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stack_model.fit(\n",
        "    np.asarray(train_logits_preds),\n",
        "    np.asarray(labels_train),\n",
        "    epochs=5, \n",
        "    batch_size=32,\n",
        "    validation_data = (np.asarray(test_logits_preds), np.asarray(labels_V2))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred = stack_model.predict(np.asarray(test_logits_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(test_set_len):\n",
        "    if np.argmax(pred[i]) == labels_V2[i] :\n",
        "        correct += 1\n",
        "        \n",
        "print(correct, correct/12630)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "gtsrbv5.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8694bb44cc80f852380ee22f251fe8a1417b8411ae9dfb95eb54c3da9ffa212b"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('vcpi2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
